{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d25bcbc",
   "metadata": {},
   "source": [
    "# Preprocessing v2 (External-style SMILES featurization)\n",
    "\n",
    "This notebook implements the SMILES → features pipeline used in `predicting-melting-point-external-dataset-score.ipynb`, adapted to this repo’s paths.\n",
    "\n",
    "**Outputs** (relative to this notebook):\n",
    "- `result/data/melting_point_features.csv`\n",
    "- (optional) `result/data/melting_point_features.parquet`\n",
    "\n",
    "Notes:\n",
    "- Canonicalizes SMILES and drops invalid/duplicate molecules.\n",
    "- Computes RDKit 2D descriptors, fragment counts, Morgan+MACCS bits, VSA bins, charge stats, cheap interaction features, and optional cached 3D shape features.\n",
    "- If a `test.csv` exists, aligns train/test feature columns like the external notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a60b1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy already installed.\n",
      "pandas already installed.\n",
      "matplotlib already installed.\n",
      "joblib already installed.\n",
      "rdkit already installed.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def ensure_package(import_name: str, install_name: str | None = None) -> None:\n",
    "    \"\"\"Install a pip package if missing (best-effort).\"\"\"\n",
    "    install_name = install_name or import_name\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, '-m', 'pip', 'list', '--format=json'],\n",
    "        check=True,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "    )\n",
    "    installed = {pkg['name'].lower() for pkg in json.loads(result.stdout)}\n",
    "    # Some packages have different import vs distribution names (e.g., rdkit-pypi -> rdkit)\n",
    "    if import_name.lower() in installed or (install_name and install_name.lower() in installed):\n",
    "        print(f'{import_name} already installed.')\n",
    "        return\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', install_name])\n",
    "    print(f'Installed {install_name} (import as {import_name}).')\n",
    "\n",
    "for pkg in [\n",
    "    ('numpy', None),\n",
    "    ('pandas', None),\n",
    "    ('matplotlib', None),\n",
    "    ('joblib', None),\n",
    "    # rdkit wheels are commonly available as rdkit-pypi (import name is rdkit)\n",
    "    ('rdkit', 'rdkit-pypi'),\n",
    "]:\n",
    "    ensure_package(*pkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "135884ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Dict, Iterable, Optional, Tuple\n",
    "\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from rdkit import Chem, rdBase, RDLogger, RDConfig\n",
    "from rdkit.Chem import AllChem, Crippen, Descriptors, Fragments, Lipinski, rdMolDescriptors, rdFingerprintGenerator, ChemicalFeatures\n",
    "from rdkit.Chem.MACCSkeys import GenMACCSKeys\n",
    "from rdkit.Chem.EState import AtomTypes as EAtomTypes\n",
    "\n",
    "try:\n",
    "    from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "except Exception:\n",
    "    MurckoScaffold = None\n",
    "\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "rdBase.DisableLog('rdApp.*')\n",
    "\n",
    "DATA_PATH = Path('../main-data/melting_point_pubchem.csv')\n",
    "\n",
    "OUTPUT_DIR = Path('result/data')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MORGAN_BITS = 512\n",
    "MORGAN_RADIUS = 2\n",
    "USE_MACCS = True\n",
    "COMPUTE_3D = True\n",
    "MAX_ITERS_3D = 0  # 0 = no optimization, >0 enables a short UFF optimize\n",
    "FEATURE_FACTORY = ChemicalFeatures.BuildFeatureFactory(Path(RDConfig.RDDataDir) / 'BaseFeatures.fdef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a6af4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (10563, 11)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Pubchem_CID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Melting_Point",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reference",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Substance_CASRN",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SMILES",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ConnectivitySMILES",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "InChI",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "InChIKey",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "IUPAC_Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Tm",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2e329c42-2da3-44ff-8509-76c6353eca88",
       "rows": [
        [
         "0",
         "Pubchem",
         "4",
         "34.5 °F",
         "\n            ",
         "78-96-6",
         "CC(CN)O",
         "CC(CN)O",
         "InChI=1S/C3H9NO/c1-3(5)2-4/h3,5H,2,4H2,1H3",
         "HXKKHQJGJAFBHI-UHFFFAOYSA-N",
         "1-aminopropan-2-ol",
         "34.5"
        ],
        [
         "1",
         "Pubchem",
         "6",
         "-54 °C",
         "\n            ",
         "97-00-7",
         "C1=CC(=C(C=C1[N+](=O)[O-])[N+](=O)[O-])Cl",
         "C1=CC(=C(C=C1[N+](=O)[O-])[N+](=O)[O-])Cl",
         "InChI=1S/C6H3ClN2O4/c7-5-2-1-4(8(10)11)3-6(5)9(12)13/h1-3H",
         "VYZAHLCBVHPDDF-UHFFFAOYSA-N",
         "1-chloro-2,4-dinitrobenzene",
         "-65.2"
        ],
        [
         "2",
         "Pubchem",
         "11",
         "-31.5 °F",
         "\n            ",
         "107-06-2",
         "C(CCl)Cl",
         "C(CCl)Cl",
         "InChI=1S/C2H4Cl2/c3-1-2-4/h1-2H2",
         "WSLDOOZREJYCGB-UHFFFAOYSA-N",
         "1,2-dichloroethane",
         "-31.5"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>Pubchem_CID</th>\n",
       "      <th>Melting_Point</th>\n",
       "      <th>reference</th>\n",
       "      <th>Substance_CASRN</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>ConnectivitySMILES</th>\n",
       "      <th>InChI</th>\n",
       "      <th>InChIKey</th>\n",
       "      <th>IUPAC_Name</th>\n",
       "      <th>Tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pubchem</td>\n",
       "      <td>4</td>\n",
       "      <td>34.5 °F</td>\n",
       "      <td>\\n</td>\n",
       "      <td>78-96-6</td>\n",
       "      <td>CC(CN)O</td>\n",
       "      <td>CC(CN)O</td>\n",
       "      <td>InChI=1S/C3H9NO/c1-3(5)2-4/h3,5H,2,4H2,1H3</td>\n",
       "      <td>HXKKHQJGJAFBHI-UHFFFAOYSA-N</td>\n",
       "      <td>1-aminopropan-2-ol</td>\n",
       "      <td>34.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pubchem</td>\n",
       "      <td>6</td>\n",
       "      <td>-54 °C</td>\n",
       "      <td>\\n</td>\n",
       "      <td>97-00-7</td>\n",
       "      <td>C1=CC(=C(C=C1[N+](=O)[O-])[N+](=O)[O-])Cl</td>\n",
       "      <td>C1=CC(=C(C=C1[N+](=O)[O-])[N+](=O)[O-])Cl</td>\n",
       "      <td>InChI=1S/C6H3ClN2O4/c7-5-2-1-4(8(10)11)3-6(5)9...</td>\n",
       "      <td>VYZAHLCBVHPDDF-UHFFFAOYSA-N</td>\n",
       "      <td>1-chloro-2,4-dinitrobenzene</td>\n",
       "      <td>-65.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pubchem</td>\n",
       "      <td>11</td>\n",
       "      <td>-31.5 °F</td>\n",
       "      <td>\\n</td>\n",
       "      <td>107-06-2</td>\n",
       "      <td>C(CCl)Cl</td>\n",
       "      <td>C(CCl)Cl</td>\n",
       "      <td>InChI=1S/C2H4Cl2/c3-1-2-4/h1-2H2</td>\n",
       "      <td>WSLDOOZREJYCGB-UHFFFAOYSA-N</td>\n",
       "      <td>1,2-dichloroethane</td>\n",
       "      <td>-31.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source  Pubchem_CID Melting_Point       reference Substance_CASRN  \\\n",
       "0  Pubchem            4       34.5 °F  \\n                     78-96-6   \n",
       "1  Pubchem            6        -54 °C  \\n                     97-00-7   \n",
       "2  Pubchem           11      -31.5 °F  \\n                    107-06-2   \n",
       "\n",
       "                                      SMILES  \\\n",
       "0                                    CC(CN)O   \n",
       "1  C1=CC(=C(C=C1[N+](=O)[O-])[N+](=O)[O-])Cl   \n",
       "2                                   C(CCl)Cl   \n",
       "\n",
       "                          ConnectivitySMILES  \\\n",
       "0                                    CC(CN)O   \n",
       "1  C1=CC(=C(C=C1[N+](=O)[O-])[N+](=O)[O-])Cl   \n",
       "2                                   C(CCl)Cl   \n",
       "\n",
       "                                               InChI  \\\n",
       "0         InChI=1S/C3H9NO/c1-3(5)2-4/h3,5H,2,4H2,1H3   \n",
       "1  InChI=1S/C6H3ClN2O4/c7-5-2-1-4(8(10)11)3-6(5)9...   \n",
       "2                   InChI=1S/C2H4Cl2/c3-1-2-4/h1-2H2   \n",
       "\n",
       "                      InChIKey                   IUPAC_Name    Tm  \n",
       "0  HXKKHQJGJAFBHI-UHFFFAOYSA-N           1-aminopropan-2-ol  34.5  \n",
       "1  VYZAHLCBVHPDDF-UHFFFAOYSA-N  1-chloro-2,4-dinitrobenzene -65.2  \n",
       "2  WSLDOOZREJYCGB-UHFFFAOYSA-N           1,2-dichloroethane -31.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv(DATA_PATH)\n",
    "print('train:', df_train.shape)\n",
    "display(df_train.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43d87d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canonicalized 10563 -> 10520 unique molecules\n"
     ]
    }
   ],
   "source": [
    "def canonicalize_smiles(smiles: Any) -> Optional[str]:\n",
    "    try:\n",
    "        if smiles is None or (isinstance(smiles, float) and np.isnan(smiles)):\n",
    "            return None\n",
    "        mol = Chem.MolFromSmiles(str(smiles))\n",
    "        if mol is None:\n",
    "            return None\n",
    "        return Chem.MolToSmiles(mol, canonical=True)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def canonicalize_frame(df: pd.DataFrame, smiles_col: str = 'SMILES') -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[smiles_col] = df[smiles_col].apply(canonicalize_smiles)\n",
    "    before = len(df)\n",
    "    df = df.dropna(subset=[smiles_col]).drop_duplicates(subset=[smiles_col], keep='last').reset_index(drop=True)\n",
    "    print(f'Canonicalized {before} -> {len(df)} unique molecules')\n",
    "    return df\n",
    "\n",
    "df_train = canonicalize_frame(df_train, 'SMILES')\n",
    "\n",
    "assert 'SMILES' in df_train.columns\n",
    "assert 'Tm' in df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eecabdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe(fn: Callable[..., Any], default: Any = 0.0) -> Callable[..., Any]:\n",
    "    def wrap(*args: Any, **kwargs: Any) -> Any:\n",
    "        try:\n",
    "            return fn(*args, **kwargs)\n",
    "        except Exception:\n",
    "            return default\n",
    "    return wrap\n",
    "\n",
    "def drop_constant_and_duplicate_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    nunique = df.nunique(dropna=False)\n",
    "    constant_cols = nunique[nunique <= 1].index.tolist()\n",
    "    df = df.drop(columns=constant_cols)\n",
    "    df = df.loc[:, ~df.T.duplicated(keep='first')]\n",
    "    return df\n",
    "\n",
    "def reduce_memory_usage(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if str(col_type) in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if pd.isna(c_min) or pd.isna(c_max):\n",
    "                continue\n",
    "            if str(col_type).startswith('int'):\n",
    "                if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "            else:\n",
    "                if c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "        elif col_type == object:\n",
    "            num_unique = df[col].nunique(dropna=False)\n",
    "            if num_unique / max(len(df), 1) < 0.5:\n",
    "                df[col] = df[col].astype('category')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b7c88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _count_atoms(m: Optional[Chem.Mol], symbols: Iterable[str]) -> int:\n",
    "    if m is None:\n",
    "        return 0\n",
    "    s = set(symbols)\n",
    "    return sum(1 for a in m.GetAtoms() if a.GetSymbol() in s)\n",
    "\n",
    "def _largest_ring_size(m: Optional[Chem.Mol]) -> int:\n",
    "    if m is None:\n",
    "        return 0\n",
    "    ri = m.GetRingInfo()\n",
    "    return max((len(r) for r in ri.AtomRings()), default=0)\n",
    "\n",
    "def count_explicit_h(m: Optional[Chem.Mol]) -> int:\n",
    "    if m is None:\n",
    "        return 0\n",
    "    mH = Chem.AddHs(m)\n",
    "    return sum(1 for a in mH.GetAtoms() if a.GetSymbol() == 'H')\n",
    "\n",
    "def gasteiger_stats(m: Optional[Chem.Mol]) -> Dict[str, float]:\n",
    "    if m is None:\n",
    "        return {'Gasteiger_q_sum': 0.0, 'Gasteiger_q_abs_sum': 0.0, 'Gasteiger_q_min': 0.0, 'Gasteiger_q_max': 0.0, 'Gasteiger_q_std': 0.0}\n",
    "    mH = Chem.AddHs(m)\n",
    "    try:\n",
    "        AllChem.ComputeGasteigerCharges(mH)\n",
    "    except Exception:\n",
    "        return {'Gasteiger_q_sum': 0.0, 'Gasteiger_q_abs_sum': 0.0, 'Gasteiger_q_min': 0.0, 'Gasteiger_q_max': 0.0, 'Gasteiger_q_std': 0.0}\n",
    "    vals: list[float] = []\n",
    "    for a in mH.GetAtoms():\n",
    "        try:\n",
    "            v = float(a.GetProp('_GasteigerCharge')) if a.HasProp('_GasteigerCharge') else 0.0\n",
    "        except Exception:\n",
    "            v = 0.0\n",
    "        if pd.isna(v) or v in (float('inf'), float('-inf')):\n",
    "            v = 0.0\n",
    "        vals.append(v)\n",
    "    arr = np.asarray(vals, dtype=float)\n",
    "    return {\n",
    "        'Gasteiger_q_sum': float(arr.sum()),\n",
    "        'Gasteiger_q_abs_sum': float(np.abs(arr).sum()),\n",
    "        'Gasteiger_q_min': float(arr.min(initial=0.0)),\n",
    "        'Gasteiger_q_max': float(arr.max(initial=0.0)),\n",
    "        'Gasteiger_q_std': float(arr.std(ddof=0)),\n",
    "    }\n",
    "\n",
    "def _smiles_morphology(smi: str) -> Dict[str, int]:\n",
    "    if not smi:\n",
    "        return {'SMI_len': 0, 'SMI_branches': 0, 'SMI_ringDigits': 0, 'SMI_stereoAt': 0, 'SMI_ezSlashes': 0}\n",
    "    return {\n",
    "        'SMI_len': len(smi),\n",
    "        'SMI_branches': smi.count('('),\n",
    "        'SMI_ringDigits': sum(ch.isdigit() for ch in smi),\n",
    "        'SMI_stereoAt': smi.count('@'),\n",
    "        'SMI_ezSlashes': smi.count('/') + smi.count('\\\\'),\n",
    "    }\n",
    "\n",
    "def _estate_stats(m: Optional[Chem.Mol]) -> Dict[str, float]:\n",
    "    if m is None:\n",
    "        return {'EState_sum': 0.0, 'EState_mean': 0.0, 'EState_max': 0.0, 'EState_min': 0.0, 'EState_std': 0.0}\n",
    "    try:\n",
    "        vals = EAtomTypes.EStateIndices(m)\n",
    "        if not vals:\n",
    "            return {'EState_sum': 0.0, 'EState_mean': 0.0, 'EState_max': 0.0, 'EState_min': 0.0, 'EState_std': 0.0}\n",
    "        arr = np.asarray(vals, dtype=float)\n",
    "        return {\n",
    "            'EState_sum': float(arr.sum()),\n",
    "            'EState_mean': float(arr.mean()),\n",
    "            'EState_max': float(arr.max()),\n",
    "            'EState_min': float(arr.min()),\n",
    "            'EState_std': float(arr.std(ddof=0)),\n",
    "        }\n",
    "    except Exception:\n",
    "        return {'EState_sum': 0.0, 'EState_mean': 0.0, 'EState_max': 0.0, 'EState_min': 0.0, 'EState_std': 0.0}\n",
    "\n",
    "def _bond_order(b: Chem.Bond) -> float:\n",
    "    if b.GetIsAromatic():\n",
    "        return 1.5\n",
    "    t = b.GetBondType()\n",
    "    if t == Chem.BondType.SINGLE:\n",
    "        return 1.0\n",
    "    if t == Chem.BondType.DOUBLE:\n",
    "        return 2.0\n",
    "    if t == Chem.BondType.TRIPLE:\n",
    "        return 3.0\n",
    "    return 0.0\n",
    "\n",
    "def _ring_size_hist(m: Optional[Chem.Mol]) -> Tuple[Dict[int, int], int]:\n",
    "    if m is None:\n",
    "        return {5: 0, 6: 0, 7: 0, 8: 0}, 0\n",
    "    ri = m.GetRingInfo()\n",
    "    sizes = [len(r) for r in ri.AtomRings()]\n",
    "    out = {5: 0, 6: 0, 7: 0, 8: 0}\n",
    "    for s in sizes:\n",
    "        if s in out:\n",
    "            out[s] += 1\n",
    "    return out, len(sizes)\n",
    "\n",
    "def _ring_systems_count(m: Optional[Chem.Mol]) -> int:\n",
    "    if m is None:\n",
    "        return 0\n",
    "    ri = m.GetRingInfo()\n",
    "    rings = [set(r) for r in ri.AtomRings()]\n",
    "    if not rings:\n",
    "        return 0\n",
    "    seen: set[int] = set()\n",
    "    systems = 0\n",
    "    for i in range(len(rings)):\n",
    "        if i in seen:\n",
    "            continue\n",
    "        systems += 1\n",
    "        stack = [i]\n",
    "        seen.add(i)\n",
    "        while stack:\n",
    "            j = stack.pop()\n",
    "            for k in range(len(rings)):\n",
    "                if k in seen:\n",
    "                    continue\n",
    "                if rings[j] & rings[k]:\n",
    "                    seen.add(k)\n",
    "                    stack.append(k)\n",
    "    return systems\n",
    "\n",
    "def _murcko_stats(m: Optional[Chem.Mol]) -> Dict[str, int]:\n",
    "    if m is None or MurckoScaffold is None:\n",
    "        return {'MurckoAtoms': 0, 'MurckoRings': 0, 'MurckoRingSystems': 0, 'SideChainAtoms': 0 if m is None else m.GetNumAtoms()}\n",
    "    try:\n",
    "        scaf = MurckoScaffold.GetScaffoldForMol(m)\n",
    "        if scaf is None or scaf.GetNumAtoms() == 0:\n",
    "            return {'MurckoAtoms': 0, 'MurckoRings': 0, 'MurckoRingSystems': 0, 'SideChainAtoms': m.GetNumAtoms()}\n",
    "        return {\n",
    "            'MurckoAtoms': int(scaf.GetNumAtoms()),\n",
    "            'MurckoRings': int(rdMolDescriptors.CalcNumRings(scaf)),\n",
    "            'MurckoRingSystems': int(_ring_systems_count(scaf)),\n",
    "            'SideChainAtoms': int(max(m.GetNumAtoms() - scaf.GetNumAtoms(), 0)),\n",
    "        }\n",
    "    except Exception:\n",
    "        return {'MurckoAtoms': 0, 'MurckoRings': 0, 'MurckoRingSystems': 0, 'SideChainAtoms': m.GetNumAtoms()}\n",
    "\n",
    "def _intramol_hbond_stats(\n",
    "    m: Optional[Chem.Mol],\n",
    "    embed_3d: bool = False,\n",
    "    maxIters: int = 50,\n",
    "    dist_cutoff: float = 3.2,\n",
    "    max_topo_path: int = 6,\n",
    ") -> Dict[str, float]:\n",
    "    if m is None:\n",
    "        return {\n",
    "            'IntraHBond_topo': 0,\n",
    "            'IntraHBond_minPath': 0,\n",
    "            'IntraHBond_3D': 0,\n",
    "            'IntraHBond_minDist3D': 0.0,\n",
    "            'IntraHBond_pairs': 0,\n",
    "        }\n",
    "\n",
    "    feats = FEATURE_FACTORY.GetFeaturesForMol(m)\n",
    "    donors = [f.GetAtomIds()[0] for f in feats if f.GetFamily() == 'Donor']\n",
    "    acceptors = [f.GetAtomIds()[0] for f in feats if f.GetFamily() == 'Acceptor']\n",
    "    if not donors or not acceptors:\n",
    "        return {\n",
    "            'IntraHBond_topo': 0,\n",
    "            'IntraHBond_minPath': 0,\n",
    "            'IntraHBond_3D': 0,\n",
    "            'IntraHBond_minDist3D': 0.0,\n",
    "            'IntraHBond_pairs': 0,\n",
    "        }\n",
    "\n",
    "    topo = Chem.GetDistanceMatrix(m)  # bond-distance matrix\n",
    "    paths = [topo[d, a] for d in donors for a in acceptors if d != a]\n",
    "    min_path = float(np.min(paths)) if paths else 0.0\n",
    "    topo_possible = int(min_path > 0 and min_path <= max_topo_path)\n",
    "\n",
    "    out = {\n",
    "        'IntraHBond_topo': topo_possible,\n",
    "        'IntraHBond_minPath': float(min_path),\n",
    "        'IntraHBond_pairs': float(len(paths)),\n",
    "        'IntraHBond_3D': 0,\n",
    "        'IntraHBond_minDist3D': 0.0,\n",
    "    }\n",
    "\n",
    "    if embed_3d:\n",
    "        try:\n",
    "            m3d = Chem.AddHs(Chem.Mol(m))\n",
    "            params = AllChem.ETKDGv3() if hasattr(AllChem, 'ETKDGv3') else AllChem.ETKDG()\n",
    "            params.randomSeed = 123\n",
    "            params.useRandomCoords = True\n",
    "            cid = AllChem.EmbedMolecule(m3d, params)\n",
    "            if cid >= 0 and maxIters > 0:\n",
    "                with Chem.WrapLogs():\n",
    "                    AllChem.UFFOptimizeMolecule(m3d, confId=cid, maxIters=maxIters)\n",
    "            conf = m3d.GetConformer()\n",
    "            coords = conf.GetPositions()\n",
    "            dists = []\n",
    "            for d in donors:\n",
    "                for a in acceptors:\n",
    "                    if d == a:\n",
    "                        continue\n",
    "                    dists.append(float(np.linalg.norm(coords[d] - coords[a])))\n",
    "            if dists:\n",
    "                min_dist = float(min(dists))\n",
    "                out['IntraHBond_minDist3D'] = min_dist\n",
    "                out['IntraHBond_3D'] = int(min_dist <= dist_cutoff)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def augment_extra_cheaps(row: Dict[str, Any], m: Optional[Chem.Mol]) -> Dict[str, Any]:\n",
    "    if m is None:\n",
    "        row.update({'FracSingle': 0.0, 'FracDouble': 0.0, 'FracTriple': 0.0, 'FracAromatic': 0.0, 'MeanBondOrder': 0.0, 'UnsatBondCount': 0})\n",
    "        row.update({'Rings5': 0, 'Rings6': 0, 'Rings7': 0, 'Rings8': 0, 'RingSystems': 0, 'Rings56_frac': 0.0})\n",
    "        row.update({'FormalCharge': 0, 'IsZwitterion': 0})\n",
    "        row.update(_estate_stats(m))\n",
    "        row.update(_murcko_stats(m))\n",
    "        row.update(_smiles_morphology(''))\n",
    "        return row\n",
    "\n",
    "    row.update(_estate_stats(m))\n",
    "    bonds = list(m.GetBonds())  \n",
    "    nb = max(len(bonds), 1)\n",
    "    n_single = sum(1 for b in bonds if b.GetBondType() == Chem.BondType.SINGLE and not b.GetIsAromatic())\n",
    "    n_double = sum(1 for b in bonds if b.GetBondType() == Chem.BondType.DOUBLE)\n",
    "    n_triple = sum(1 for b in bonds if b.GetBondType() == Chem.BondType.TRIPLE)\n",
    "    n_arom = sum(1 for b in bonds if b.GetIsAromatic())\n",
    "    row['FracSingle'] = n_single / nb\n",
    "    row['FracDouble'] = n_double / nb\n",
    "    row['FracTriple'] = n_triple / nb\n",
    "    row['FracAromatic'] = n_arom / nb\n",
    "    row['MeanBondOrder'] = (sum(_bond_order(b) for b in bonds) / nb) if nb else 0.0\n",
    "    row['UnsatBondCount'] = int(n_double + n_triple + n_arom)\n",
    "\n",
    "    hist, n_rings = _ring_size_hist(m)\n",
    "    row['Rings5'] = int(hist[5])\n",
    "    row['Rings6'] = int(hist[6])\n",
    "    row['Rings7'] = int(hist[7])\n",
    "    row['Rings8'] = int(hist[8])\n",
    "    row['RingSystems'] = int(_ring_systems_count(m))\n",
    "    row['Rings56_frac'] = (hist[5] + hist[6]) / (n_rings if n_rings > 0 else 1)\n",
    "\n",
    "    row.update(_murcko_stats(m))\n",
    "    tot_charge = sum(a.GetFormalCharge() for a in m.GetAtoms())\n",
    "    has_pos = any(a.GetFormalCharge() > 0 for a in m.GetAtoms())\n",
    "    has_neg = any(a.GetFormalCharge() < 0 for a in m.GetAtoms())\n",
    "    row['FormalCharge'] = int(tot_charge)\n",
    "    row['IsZwitterion'] = int(has_pos and has_neg)\n",
    "\n",
    "    try:\n",
    "        smi = Chem.MolToSmiles(m, canonical=True)\n",
    "    except Exception:\n",
    "        smi = ''\n",
    "    row.update(_smiles_morphology(smi))\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6da6b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shape3d_from_cansmi(cansmi: str, maxIters: int = 0) -> Tuple[str, Dict[str, float]]:\n",
    "    \"\"\"Compute lean 3D shape features for ONE canonical SMILES.\"\"\"\n",
    "    try:\n",
    "        m = Chem.MolFromSmiles(cansmi)\n",
    "        if m is None:\n",
    "            return cansmi, {}\n",
    "\n",
    "        mH = Chem.AddHs(m)\n",
    "        params = AllChem.ETKDGv3() if hasattr(AllChem, 'ETKDGv3') else AllChem.ETKDG()\n",
    "        params.randomSeed = 123\n",
    "        params.useRandomCoords = True\n",
    "\n",
    "        with Chem.WrapLogs():\n",
    "            cid = AllChem.EmbedMolecule(mH, params)\n",
    "        if cid < 0:\n",
    "            with Chem.WrapLogs():\n",
    "                cid = AllChem.EmbedMolecule(mH, randomSeed=123)\n",
    "            if cid < 0:\n",
    "                return cansmi, {}\n",
    "\n",
    "        if maxIters and maxIters > 0:\n",
    "            try:\n",
    "                with Chem.WrapLogs():\n",
    "                    AllChem.UFFOptimizeMolecule(mH, confId=cid, maxIters=int(maxIters))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        m_noH = Chem.RemoveHs(mH)\n",
    "        confId = 0\n",
    "\n",
    "        out: Dict[str, float] = {}\n",
    "        for nm, fn in [\n",
    "            ('RadiusOfGyration', rdMolDescriptors.CalcRadiusOfGyration),\n",
    "            ('InertialShapeFactor', rdMolDescriptors.CalcInertialShapeFactor),\n",
    "            ('PMI1', rdMolDescriptors.CalcPMI1),\n",
    "            ('PMI2', rdMolDescriptors.CalcPMI2),\n",
    "            ('PMI3', rdMolDescriptors.CalcPMI3),\n",
    "            ('NPR1', rdMolDescriptors.CalcNPR1),\n",
    "            ('NPR2', rdMolDescriptors.CalcNPR2),\n",
    "        ]:\n",
    "            try:\n",
    "                with Chem.WrapLogs():\n",
    "                    out[nm] = float(fn(m_noH, confId=confId))\n",
    "            except Exception:\n",
    "                out[nm] = 0.0\n",
    "\n",
    "        pmi1 = out.get('PMI1', 0.0) or 0.0\n",
    "        pmi2 = out.get('PMI2', 0.0) or 0.0\n",
    "        pmi3 = out.get('PMI3', 0.0) or 0.0\n",
    "        out['PMI2_over_PMI1'] = (pmi2 / pmi1) if pmi1 else 0.0\n",
    "        out['PMI3_over_PMI1'] = (pmi3 / pmi1) if pmi1 else 0.0\n",
    "        return cansmi, out\n",
    "    except Exception:\n",
    "        return cansmi, {}\n",
    "\n",
    "def precompute_shape3d_cache(smiles_series: pd.Series, n_jobs: Optional[int] = None, maxIters: int = 0) -> Dict[str, Dict[str, float]]:\n",
    "    n_jobs = n_jobs if n_jobs is not None else max(1, mp.cpu_count() - 1)\n",
    "    can = smiles_series.astype(str).apply(lambda s: canonicalize_smiles(s))\n",
    "    uniq = sorted(x for x in set(can.tolist()) if x is not None)\n",
    "    if not uniq:\n",
    "        return {}\n",
    "    results = Parallel(n_jobs=n_jobs, backend='loky', batch_size=64)(\n",
    "        delayed(_shape3d_from_cansmi)(s, maxIters=maxIters) for s in uniq\n",
    "    )\n",
    "    return {k: v for k, v in results if k is not None}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2db6014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rdkit_feature_row(m: Optional[Chem.Mol], compute_3d: bool = False, shape_cache: Optional[Dict[str, Dict[str, float]]] = None) -> Dict[str, Any]:\n",
    "    row: Dict[str, Any] = {}\n",
    "\n",
    "    for name, func in Descriptors._descList:\n",
    "        row[name] = _safe(func, np.nan)(m)\n",
    "\n",
    "    row['MolLogP'] = _safe(Crippen.MolLogP, np.nan)(m)\n",
    "    row['MolMR'] = _safe(Crippen.MolMR, np.nan)(m)\n",
    "    row['NumHAcceptors'] = _safe(Lipinski.NumHAcceptors, np.nan)(m)\n",
    "    row['NumHDonors'] = _safe(Lipinski.NumHDonors, np.nan)(m)\n",
    "    row['NumRings'] = _safe(rdMolDescriptors.CalcNumRings, 0)(m)\n",
    "    row['NumAromaticRings'] = _safe(rdMolDescriptors.CalcNumAromaticRings, 0)(m)\n",
    "    row['NumAliphaticRings'] = _safe(rdMolDescriptors.CalcNumAliphaticRings, 0)(m)\n",
    "    row['NumSaturatedRings'] = _safe(rdMolDescriptors.CalcNumSaturatedRings, 0)(m)\n",
    "    row['NumBridgeheadAtoms'] = _safe(rdMolDescriptors.CalcNumBridgeheadAtoms, 0)(m)\n",
    "    row['NumSpiroAtoms'] = _safe(rdMolDescriptors.CalcNumSpiroAtoms, 0)(m)\n",
    "    row['LargestRingSize'] = _safe(_largest_ring_size, 0)(m)\n",
    "    row['NumAmideBonds'] = _safe(rdMolDescriptors.CalcNumAmideBonds, 0)(m)\n",
    "    row['TPSA'] = _safe(rdMolDescriptors.CalcTPSA, np.nan)(m)\n",
    "    row['LabuteASA'] = _safe(rdMolDescriptors.CalcLabuteASA, np.nan)(m)\n",
    "\n",
    "    if m is None:\n",
    "        for el in ['C','H','N','O','S','F','Cl','Br','I','P']:\n",
    "            row[f'Count_{el}'] = 0\n",
    "    else:\n",
    "        for el in ['C','N','O','S','F','Cl','Br','I','P']:\n",
    "            row[f'Count_{el}'] = _count_atoms(m, [el])\n",
    "        row['Count_H'] = _safe(count_explicit_h, 0)(m)\n",
    "\n",
    "    for attr in dir(Fragments):\n",
    "        if attr.startswith('fr_'):\n",
    "            fn = getattr(Fragments, attr)\n",
    "            if callable(fn):\n",
    "                row[attr] = _safe(fn, 0)(m)\n",
    "\n",
    "    try:\n",
    "        if m is not None:\n",
    "            mgen = rdFingerprintGenerator.GetMorganGenerator(radius=MORGAN_RADIUS, fpSize=MORGAN_BITS, countSimulation=False)\n",
    "            mfp = mgen.GetFingerprint(m)\n",
    "            for i in range(MORGAN_BITS):\n",
    "                row[f'Morgan_{i}'] = int(mfp[i])\n",
    "        else:\n",
    "            for i in range(MORGAN_BITS):\n",
    "                row[f'Morgan_{i}'] = 0\n",
    "        if USE_MACCS:\n",
    "            if m is not None:\n",
    "                maccs = GenMACCSKeys(m)\n",
    "                for i in range(len(maccs)):\n",
    "                    row[f'MACCS_{i}'] = int(maccs[i])\n",
    "            else:\n",
    "                for i in range(167):\n",
    "                    row[f'MACCS_{i}'] = 0\n",
    "    except Exception:\n",
    "        for i in range(MORGAN_BITS):\n",
    "            row.setdefault(f'Morgan_{i}', 0)\n",
    "        if USE_MACCS:\n",
    "            for i in range(167):\n",
    "                row.setdefault(f'MACCS_{i}', 0)\n",
    "\n",
    "    for vsa_name, vsa_fn in [\n",
    "        ('SlogP_VSA', getattr(rdMolDescriptors, 'SlogP_VSA_', None)),\n",
    "        ('SMR_VSA', getattr(rdMolDescriptors, 'SMR_VSA_', None)),\n",
    "        ('EState_VSA', getattr(rdMolDescriptors, 'EState_VSA_', None)),\n",
    "    ]:\n",
    "        if vsa_fn is None or m is None:\n",
    "            continue\n",
    "        try:\n",
    "            bins = vsa_fn(m)\n",
    "            for i, val in enumerate(bins):\n",
    "                row[f'{vsa_name}{i}'] = float(val)\n",
    "            row[f'{vsa_name}_sum'] = float(sum(bins))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    row.update(_safe(gasteiger_stats, {})(m))\n",
    "\n",
    "    if compute_3d and m is not None:\n",
    "        try:\n",
    "            cansmi = Chem.MolToSmiles(m, canonical=True)\n",
    "        except Exception:\n",
    "            cansmi = None\n",
    "        if shape_cache is not None and cansmi in shape_cache:\n",
    "            row.update(shape_cache[cansmi])\n",
    "        elif cansmi is not None:\n",
    "            _, quick = _shape3d_from_cansmi(cansmi, maxIters=MAX_ITERS_3D)\n",
    "            row.update(quick)\n",
    "\n",
    "    hbd = float(row.get('NumHDonors', 0.0) or 0.0)\n",
    "    hba = float(row.get('NumHAcceptors', 0.0) or 0.0)\n",
    "    mw = float(row.get('MolWt', 0.0) or 0.0)\n",
    "    hat = float(row.get('HeavyAtomCount', 0.0) or 1.0)\n",
    "    tpsa = float(row.get('TPSA', 0.0) or 0.0)\n",
    "    nrot = float(row.get('NumRotatableBonds', 0.0) or 0.0)\n",
    "    narm = float(row.get('NumAromaticRings', 0.0) or 0.0)\n",
    "    mollogp = float(row.get('MolLogP', 0.0) or 0.0)\n",
    "    bertz = float(row.get('BertzCT', 0.0) or 0.0)\n",
    "\n",
    "    row['HBondCapacity'] = hbd + hba\n",
    "    row['HBondDensity_perHeavyAtom'] = (hbd + hba) / hat\n",
    "    row['RingDensity_perHeavyAtom'] = float(row.get('NumRings', 0.0) or 0.0) / hat\n",
    "    row['HalogenCount'] = float(row.get('Count_F', 0) + row.get('Count_Cl', 0) + row.get('Count_Br', 0) + row.get('Count_I', 0))\n",
    "    row['HeteroAtomFrac'] = float(row.get('Count_N', 0) + row.get('Count_O', 0) + row.get('Count_S', 0) + row.get('Count_P', 0)) / hat\n",
    "    row['AromRingFrac'] = float(row.get('NumAromaticRings', 0.0) or 0.0) / float((row.get('NumRings', 1.0) or 1.0))\n",
    "\n",
    "    row['HBond_Product'] = hbd * hba\n",
    "    row['LogP_div_TPSA'] = mollogp / (tpsa + 1.0)\n",
    "    row['LogP_x_TPSA'] = mollogp * tpsa\n",
    "    row['Flexibility_Score'] = nrot / (mw + 1.0)\n",
    "    row['MolWt_x_AromaticRings'] = mw * narm\n",
    "    row['Complexity_per_MW'] = bertz / (mw + 1.0)\n",
    "    row['Rigidity_Score'] = narm / (nrot + 1.0)\n",
    "    row.update(_intramol_hbond_stats(m, embed_3d=compute_3d, maxIters=MAX_ITERS_3D))\n",
    "    row = augment_extra_cheaps(row, m)\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "165df576",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def featurize_smiles(df: pd.DataFrame, compute_3d: bool = True, maxIters_3d: int = 0) -> pd.DataFrame:\n",
    "    shape_cache = None\n",
    "    if compute_3d:\n",
    "        shape_cache = precompute_shape3d_cache(df['SMILES'], n_jobs=-1, maxIters=maxIters_3d)\n",
    "    mols = df['SMILES'].apply(lambda s: Chem.MolFromSmiles(s) if pd.notna(s) else None)\n",
    "    feats = [rdkit_feature_row(m, compute_3d=compute_3d, shape_cache=shape_cache) for m in mols]\n",
    "    feats = pd.DataFrame(feats)\n",
    "    feats = drop_constant_and_duplicate_columns(feats)\n",
    "    out = pd.concat([df.reset_index(drop=True), feats.reset_index(drop=True)], axis=1)\n",
    "    out = reduce_memory_usage(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b47b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:46:01] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "df_train_subset = df_train[['SMILES', 'Tm']].copy()\n",
    "\n",
    "df_train_feat = featurize_smiles(df_train_subset, compute_3d=COMPUTE_3D, maxIters_3d=MAX_ITERS_3D)\n",
    "print('train featurized:', df_train_feat.shape)\n",
    "\n",
    "display(df_train_feat.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8694f72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chem_type\n",
      "organic (heteroatom-containing)            9246\n",
      "metal-containing (coordination/complex)     623\n",
      "hydrocarbon                                 269\n",
      "halogenated hydrocarbon                     221\n",
      "inorganic (non-carbon)                      113\n",
      "inorganic ionic                              45\n",
      "unknown                                       3\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21875/119039392.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_train_feat[\"chem_type\"] = df_train_feat[\"SMILES\"].fillna(\"\").astype(str).apply(classify_smiles)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n",
    "try:\n",
    "    from rdkit import Chem\n",
    "    RDKit_AVAILABLE = True\n",
    "except Exception:\n",
    "    RDKit_AVAILABLE = False\n",
    "\n",
    "# 2) metal symbols (common metals + lanthanides/actinides can be extended)\n",
    "METALS = {\n",
    "    \"Li\",\"Be\",\"Na\",\"Mg\",\"Al\",\"K\",\"Ca\",\"Sc\",\"Ti\",\"V\",\"Cr\",\"Mn\",\"Fe\",\"Co\",\"Ni\",\"Cu\",\"Zn\",\n",
    "    \"Ga\",\"Ge\",\"Rb\",\"Sr\",\"Y\",\"Zr\",\"Nb\",\"Mo\",\"Tc\",\"Ru\",\"Rh\",\"Pd\",\"Ag\",\"Cd\",\"In\",\"Sn\",\n",
    "    \"Cs\",\"Ba\",\"La\",\"Ce\",\"Pr\",\"Nd\",\"Pm\",\"Sm\",\"Eu\",\" Gd\",\"Tb\",\"Dy\",\"Ho\",\"Er\",\"Tm\",\"Yb\",\n",
    "    \"Lu\",\"Hf\",\"Ta\",\"W\",\"Re\",\"Os\",\"Ir\",\"Pt\",\"Au\",\"Hg\",\"Tl\",\"Pb\",\"Bi\",\"Po\",\"Fr\",\"Ra\",\n",
    "    \"Ac\",\"Th\",\"Pa\",\"U\",\"Np\",\"Pu\"\n",
    "}\n",
    "# clean METALS spacing issues:\n",
    "METALS = {m.strip() for m in METALS}\n",
    "\n",
    "# 3) helper to get element symbols from SMILES (RDKit preferred)\n",
    "elem_re = re.compile(r'([A-Z][a-z]?)')\n",
    "def elements_from_smiles_rdkit(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return set()\n",
    "    return {atom.GetSymbol() for atom in mol.GetAtoms()}\n",
    "\n",
    "def elements_from_smiles_regex(smiles):\n",
    "    # remove isotopes like 12C and bracket contents' internal digits for simpler parsing\n",
    "    s = re.sub(r'\\[.*?\\]', lambda m: re.sub(r'\\d+','',m.group(0)), smiles)\n",
    "    return set(elem_re.findall(s))\n",
    "\n",
    "def get_elements(smiles):\n",
    "    if RDKit_AVAILABLE:\n",
    "        el = elements_from_smiles_rdkit(smiles)\n",
    "        if el:\n",
    "            return el\n",
    "    return elements_from_smiles_regex(smiles)\n",
    "\n",
    "# 4) classifier\n",
    "def classify_smiles(smiles):\n",
    "    if not isinstance(smiles, str) or smiles.strip()==\"\":\n",
    "        return \"unknown\"\n",
    "    s = smiles.strip()\n",
    "    # quick ionic / explicit charge detection\n",
    "    if '+' in s or '-' in s:\n",
    "        # presence of charges in SMILES often indicates salts/ionic complexes\n",
    "        # but we still look at elements for better label\n",
    "        ionic = True\n",
    "    else:\n",
    "        ionic = False\n",
    "\n",
    "    elements = {e for e in get_elements(s) if e != 'H'}\n",
    "    if not elements:\n",
    "        return \"unknown\"\n",
    "\n",
    "    # metal-containing\n",
    "    if any(el in METALS for el in elements):\n",
    "        return \"metal-containing (coordination/complex)\"\n",
    "\n",
    "    # contains carbon?\n",
    "    if 'C' in elements:\n",
    "        # hydrocarbons: only carbon (and implicit H)\n",
    "        nonC = elements - {'C','H'}\n",
    "        if not nonC:\n",
    "            return \"hydrocarbon\"\n",
    "        # if only halogens + C -> halogenated hydrocarbon\n",
    "        halogens = {'F','Cl','Br','I'}\n",
    "        if nonC.issubset(halogens):\n",
    "            return \"halogenated hydrocarbon\"\n",
    "        # if O,N,S,P etc present -> heteroatom-containing organic\n",
    "        return \"organic (heteroatom-containing)\"\n",
    "    else:\n",
    "        # no carbon: inorganic (but could be small organometallic fragments)\n",
    "        if ionic:\n",
    "            return \"inorganic ionic\"\n",
    "        return \"inorganic (non-carbon)\"\n",
    "\n",
    "\n",
    "df_train_feat[\"chem_type\"] = df_train_feat[\"SMILES\"].fillna(\"\").astype(str).apply(classify_smiles)\n",
    "\n",
    "\n",
    "print(df_train_feat[\"chem_type\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2aa7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feat[df_train_feat[\"chem_type\"]==\"organic (heteroatom-containing)\"].to_csv(OUTPUT_DIR / \"train_organic_heteroatom_containing.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a8d4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train features to result/data/melting_point_features.csv\n",
      "Skipped parquet export: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\n",
      "A suitable version of pyarrow or fastparquet is required for parquet support.\n",
      "Trying to import the above resulted in these errors:\n",
      " - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n",
      " - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_test_feat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mSkipped parquet export: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdf_test_feat\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     14\u001b[39m     test_csv_path = OUTPUT_DIR / \u001b[33m'\u001b[39m\u001b[33mmelting_point_features_test.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     15\u001b[39m     df_test_feat.to_csv(test_csv_path, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_test_feat' is not defined"
     ]
    }
   ],
   "source": [
    "csv_path = OUTPUT_DIR / 'melting_point_features.csv'\n",
    "parquet_path = OUTPUT_DIR / 'melting_point_features.parquet'\n",
    "\n",
    "df_train_feat.to_csv(csv_path, index=False)\n",
    "print(f'Saved train features to {csv_path}')\n",
    "\n",
    "try:\n",
    "    df_train_feat.to_parquet(parquet_path, index=False)\n",
    "    print(f'Saved train features to {parquet_path}')\n",
    "except Exception as exc:\n",
    "    print(f'Skipped parquet export: {exc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a4ce58",
   "metadata": {},
   "source": [
    "# Baseline model (LightGBM)\n",
    "This section trains a simple baseline on the generated features to get first-pass metrics (MAE/RMSE/R²).\n",
    "- Uses a train/valid split.\n",
    "- Fits imputation on train only (prevents leakage).\n",
    "- Saves metrics + predictions to `result/data/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a832131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn already installed.\n",
      "lightgbm already installed.\n"
     ]
    }
   ],
   "source": [
    "# Install baseline modeling deps if missing (best-effort)\n",
    "for pkg in [\n",
    "    ('scikit-learn', 'scikit-learn'),\n",
    "    ('lightgbm', 'lightgbm'),\n",
    "]:\n",
    "    try:\n",
    "        ensure_package(pkg[0], pkg[1])\n",
    "    except Exception as exc:\n",
    "        print(f\"Package install check failed for {pkg}: {exc}\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b6b9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows used: 9246\n",
      "Numeric features: 941\n",
      "Target stats: -698.8 242.31646441704524 4892.0\n"
     ]
    }
   ],
   "source": [
    "# Build X/y from the featurized training frame\n",
    "if not 'df_train_feat' in locals():\n",
    "    df_train_feat = pd.read_csv(OUTPUT_DIR / 'melting_point_features.csv')\n",
    "\n",
    "assert 'Tm' in df_train_feat.columns, \"Expected target column 'Tm' in df_train_feat\"\n",
    "assert 'SMILES' in df_train_feat.columns, \"Expected 'SMILES' column in df_train_feat\"\n",
    "\n",
    "\n",
    "\n",
    "work_df = df_train_feat.copy()\n",
    "\n",
    "#load only organic (heteroatom-containing) compounds for baseline modeling\n",
    "work_df = work_df[work_df[\"chem_type\"]==\"organic (heteroatom-containing)\"].reset_index(drop=True)\n",
    "\n",
    "# Use numeric features only (exclude identifiers/strings)\n",
    "feature_cols = [c for c in work_df.columns if c not in ('Tm', 'SMILES')]\n",
    "X = work_df[feature_cols].select_dtypes(include=['number'])\n",
    "y = work_df['Tm'].astype(float)\n",
    "\n",
    "print('Rows used:', len(work_df))\n",
    "print('Numeric features:', X.shape[1])\n",
    "print('Target stats:', float(y.min()), float(y.mean()), float(y.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745d9dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQR bounds for Tm: [-311.687, 828.612] (Q1=115.925, Q3=401.000, IQR=285.075)\n",
      "Removed outliers: 218/9246 (2.36%)\n",
      "After outlier removal -> Rows: 9028 Numeric features: 941\n"
     ]
    }
   ],
   "source": [
    " # Outlier removal on target (IQR rule) + report percent removed\n",
    "tm = work_df['Tm'].astype(float)\n",
    "q1 = float(tm.quantile(0.25))\n",
    "q3 = float(tm.quantile(0.75))\n",
    "iqr = q3 - q1\n",
    "lower = q1 - 1.5 * iqr\n",
    "upper = q3 + 1.5 * iqr\n",
    "\n",
    "mask = (tm >= lower) & (tm <= upper)\n",
    "removed = int((~mask).sum())\n",
    "total = int(len(work_df))\n",
    "pct_removed = 100.0 * removed / total if total else 0.0\n",
    "\n",
    "print(f\"IQR bounds for Tm: [{lower:.3f}, {upper:.3f}] (Q1={q1:.3f}, Q3={q3:.3f}, IQR={iqr:.3f})\")\n",
    "print(f\"Removed outliers: {removed}/{total} ({pct_removed:.2f}%)\")\n",
    "\n",
    "# Apply filter\n",
    "work_df = work_df.loc[mask].reset_index(drop=True)\n",
    "feature_cols = [c for c in work_df.columns if c not in ('Tm', 'SMILES')]\n",
    "X = work_df[feature_cols].select_dtypes(include=['number'])\n",
    "y = work_df['Tm'].astype(float)\n",
    "\n",
    "print('After outlier removal -> Rows:', len(work_df), 'Numeric features:', X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75050b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 4.085008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 31700\n",
      "[LightGBM] [Info] Number of data points in the train set: 7222, number of used features: 916\n",
      "[LightGBM] [Info] Start training from score 254.907431\n",
      "Baseline metrics\n",
      "MAE : 80.06294283128088\n",
      "RMSE: 124.85562117579609\n",
      "R2  : 0.6040086743494542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tp_ubuntu/project/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train/valid split + train-only imputation (no leakage)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    " )\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imp = imputer.fit_transform(X_train)\n",
    "X_valid_imp = imputer.transform(X_valid)\n",
    "\n",
    "model = lgb.LGBMRegressor(\n",
    "    objective='regression',\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=63,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_imp, y_train,\n",
    "    eval_set=[(X_valid_imp, y_valid)],\n",
    "    eval_metric='l1',\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)],\n",
    ")\n",
    "\n",
    "pred_valid = model.predict(X_valid_imp, num_iteration=model.best_iteration_)\n",
    "mae = float(mean_absolute_error(y_valid, pred_valid))\n",
    "mse = float(mean_squared_error(y_valid, pred_valid))\n",
    "rmse = float(np.sqrt(mse))\n",
    "r2 = float(r2_score(y_valid, pred_valid))\n",
    "\n",
    "print('Baseline metrics')\n",
    "print('MAE :', mae)\n",
    "print('RMSE:', rmse)\n",
    "print('R2  :', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78afe9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metrics to result/data/baseline_lgbm_metrics.json\n",
      "Saved predictions to result/data/baseline_lgbm_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save baseline outputs\n",
    "baseline_metrics = {\n",
    "    'mae': mae,\n",
    "    'rmse': rmse,\n",
    "    'r2': r2,\n",
    "    'n_rows': int(len(work_df)),\n",
    "    'n_features': int(X.shape[1]),\n",
    "    'best_iteration': int(getattr(model, 'best_iteration_', 0) or 0),\n",
    "}\n",
    "\n",
    "metrics_path = OUTPUT_DIR / 'baseline_lgbm_metrics.json'\n",
    "with open(metrics_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(baseline_metrics, f, indent=2)\n",
    "print('Saved metrics to', metrics_path)\n",
    "\n",
    "pred_path = OUTPUT_DIR / 'baseline_lgbm_predictions.csv'\n",
    "pred_df = pd.DataFrame({\n",
    "    'y_true': y_valid.reset_index(drop=True),\n",
    "    'y_pred': pred_valid,\n",
    "})\n",
    "pred_df.to_csv(pred_path, index=False)\n",
    "print('Saved predictions to', pred_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
