{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba85359e",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64a22807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "df = pd.read_csv('result/data/melting_point_features.csv')\n",
    "\n",
    "y = df['Tm']\n",
    "X = df.drop(columns=['Tm'])\n",
    "\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_clean = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_clean, y, test_size=0.2, random_state=2601)\n",
    "\n",
    "base_model = LGBMRegressor(random_state=2601, n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad834c6e",
   "metadata": {},
   "source": [
    "# REMOVE OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d500dc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train Size: 8416\n",
      "Cleaned Train Size: 8115\n",
      "Removed: 301 Samp\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers(df, col):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    return df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "train_data = X_train.copy()\n",
    "train_data['Tm'] = y_train\n",
    "\n",
    "print(f\"Original Train Size: {len(train_data)}\")\n",
    "\n",
    "train_data_clean = remove_outliers(train_data, 'Tm')\n",
    "\n",
    "print(f\"Cleaned Train Size: {len(train_data_clean)}\")\n",
    "print(f\"Removed: {len(train_data) - len(train_data_clean)} Samp\")\n",
    "\n",
    "X_train_clean = train_data_clean.drop(columns=['Tm'])\n",
    "y_train_clean = train_data_clean['Tm']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e176a307",
   "metadata": {},
   "source": [
    "# RFECV Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915a736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from lightgbm import LGBMRegressor\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"\\n---START RFE ---\")\n",
    "start = time.time()\n",
    "\n",
    "model = LGBMRegressor(\n",
    "    objective='regression_l1',\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.01,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=2601,\n",
    "    n_jobs=1,\n",
    "    verbose=-1)\n",
    "\n",
    "rfe = RFECV(\n",
    "    estimator=model, \n",
    "    min_features_to_select=50,\n",
    "    step=20,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "selected_rfe = X_train.columns[rfe.support_]\n",
    "print(f\"‚è±Ô∏è Time Run: {time.time() - start:.2f} s\")\n",
    "print(f\"‚úÖ RFECV Choosen {len(selected_rfe)} features:\")\n",
    "print(list(selected_rfe))\n",
    "\n",
    "import joblib\n",
    "joblib.dump(list(selected_rfe), 'result/rfe_features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcada578",
   "metadata": {},
   "source": [
    "# GENETIC ALGORITHM (GA) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afd1addb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- üß¨ START RUN GENETIC ALGORITHM ---\n",
      "gen\tnevals\tfitness \tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t50    \t-267.764\t4.93195    \t-255.101   \t-278.156   \n",
      "1  \t92    \t-263.454\t3.98779    \t-255.101   \t-270.855   \n",
      "2  \t93    \t-259.998\t2.17209    \t-255.489   \t-265.386   \n",
      "3  \t90    \t-258.399\t1.52927    \t-255.489   \t-261.992   \n",
      "4  \t94    \t-257.449\t1.35679    \t-254.948   \t-260.049   \n",
      "5  \t89    \t-256.46 \t1.14056    \t-253.791   \t-258.827   \n",
      "6  \t85    \t-256.161\t0.848217   \t-253.791   \t-257.802   \n",
      "7  \t83    \t-255.742\t1.04772    \t-252.321   \t-258.328   \n",
      "8  \t88    \t-255.79 \t0.915433   \t-253.791   \t-258.328   \n",
      "9  \t86    \t-255.424\t0.788329   \t-254.108   \t-257.596   \n",
      "10 \t93    \t-255.258\t1.12705    \t-252.941   \t-257.705   \n",
      "11 \t91    \t-254.679\t1.07367    \t-252.941   \t-257.705   \n",
      "12 \t89    \t-254.393\t0.989895   \t-252.941   \t-256.391   \n",
      "13 \t91    \t-254.473\t1.02966    \t-252.941   \t-256.832   \n",
      "14 \t94    \t-254.008\t0.748887   \t-251.927   \t-255.395   \n",
      "15 \t93    \t-253.849\t0.792186   \t-252.798   \t-256.287   \n",
      "‚è±Ô∏è Time Run: 1928.28 s\n",
      "\n",
      "‚úÖ GA Choosen 494 features:\n",
      "\\List Features:\n",
      "['MaxEStateIndex', 'HeavyAtomMolWt', 'ExactMolWt', 'NumValenceElectrons', 'NumRadicalElectrons', 'MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'MinAbsPartialCharge', 'AvgIpc', 'BalabanJ', 'Chi0v', 'Chi1v', 'Chi2v', 'Chi3v', 'Ipc', 'Kappa3', 'PEOE_VSA1', 'PEOE_VSA12', 'PEOE_VSA13', 'PEOE_VSA14', 'PEOE_VSA2', 'PEOE_VSA5', 'PEOE_VSA6', 'PEOE_VSA7', 'SMR_VSA1', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA5', 'SMR_VSA8', 'SlogP_VSA1', 'SlogP_VSA2', 'SlogP_VSA5', 'TPSA', 'EState_VSA11', 'EState_VSA2', 'EState_VSA6', 'EState_VSA7', 'EState_VSA9', 'VSA_EState1', 'VSA_EState2', 'VSA_EState3', 'VSA_EState4', 'VSA_EState6', 'VSA_EState7', 'VSA_EState8', 'VSA_EState9', 'FractionCSP3', 'HeavyAtomCount', 'NHOHCount', 'NOCount', 'NumAliphaticRings', 'NumAromaticCarbocycles', 'NumAromaticRings', 'NumAtomStereoCenters', 'NumBridgeheadAtoms', 'NumHAcceptors', 'NumHDonors', 'NumHeterocycles', 'NumRotatableBonds', 'NumSaturatedRings', 'NumSpiroAtoms', 'NumUnspecifiedAtomStereoCenters', 'Phi', 'RingCount', 'MolLogP', 'fr_Al_OH', 'fr_Ar_COO', 'fr_Ar_NH', 'fr_Ar_OH', 'fr_COO', 'fr_C_S', 'fr_HOCCN', 'fr_Imine', 'fr_NH0', 'fr_NH1', 'fr_NH2', 'fr_N_O', 'fr_Ndealkylation2', 'fr_aldehyde', 'fr_allylic_oxid', 'fr_amidine', 'fr_aryl_methyl', 'fr_azo', 'fr_barbitur', 'fr_benzodiazepine', 'fr_bicyclic', 'fr_dihydropyridine', 'fr_furan', 'fr_guanido', 'fr_hdrzone', 'fr_isocyan', 'fr_isothiocyan', 'fr_ketone', 'fr_ketone_Topliss', 'fr_lactam', 'fr_lactone', 'fr_morpholine', 'fr_nitro', 'fr_nitro_arom', 'fr_oxazole', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_phos_ester', 'fr_pyridine', 'fr_quatN', 'fr_tetrazole', 'fr_thiocyan', 'fr_thiophene', 'fr_unbrch_alkane', 'LargestRingSize', 'Count_N', 'Count_S', 'Count_Cl', 'Count_P', 'Count_H', 'Morgan_2', 'Morgan_3', 'Morgan_6', 'Morgan_7', 'Morgan_8', 'Morgan_11', 'Morgan_13', 'Morgan_15', 'Morgan_16', 'Morgan_17', 'Morgan_21', 'Morgan_22', 'Morgan_23', 'Morgan_24', 'Morgan_25', 'Morgan_26', 'Morgan_27', 'Morgan_28', 'Morgan_29', 'Morgan_30', 'Morgan_31', 'Morgan_33', 'Morgan_34', 'Morgan_35', 'Morgan_36', 'Morgan_37', 'Morgan_39', 'Morgan_43', 'Morgan_44', 'Morgan_48', 'Morgan_49', 'Morgan_52', 'Morgan_53', 'Morgan_54', 'Morgan_56', 'Morgan_58', 'Morgan_65', 'Morgan_68', 'Morgan_69', 'Morgan_70', 'Morgan_72', 'Morgan_73', 'Morgan_76', 'Morgan_77', 'Morgan_81', 'Morgan_84', 'Morgan_85', 'Morgan_86', 'Morgan_88', 'Morgan_89', 'Morgan_91', 'Morgan_92', 'Morgan_93', 'Morgan_95', 'Morgan_96', 'Morgan_97', 'Morgan_98', 'Morgan_99', 'Morgan_100', 'Morgan_101', 'Morgan_103', 'Morgan_104', 'Morgan_107', 'Morgan_109', 'Morgan_113', 'Morgan_117', 'Morgan_119', 'Morgan_120', 'Morgan_121', 'Morgan_124', 'Morgan_125', 'Morgan_127', 'Morgan_130', 'Morgan_131', 'Morgan_133', 'Morgan_135', 'Morgan_138', 'Morgan_143', 'Morgan_144', 'Morgan_145', 'Morgan_146', 'Morgan_147', 'Morgan_148', 'Morgan_151', 'Morgan_153', 'Morgan_156', 'Morgan_158', 'Morgan_163', 'Morgan_164', 'Morgan_165', 'Morgan_166', 'Morgan_169', 'Morgan_172', 'Morgan_174', 'Morgan_175', 'Morgan_176', 'Morgan_177', 'Morgan_181', 'Morgan_182', 'Morgan_183', 'Morgan_184', 'Morgan_186', 'Morgan_189', 'Morgan_190', 'Morgan_192', 'Morgan_193', 'Morgan_194', 'Morgan_200', 'Morgan_201', 'Morgan_205', 'Morgan_208', 'Morgan_211', 'Morgan_216', 'Morgan_217', 'Morgan_220', 'Morgan_232', 'Morgan_233', 'Morgan_234', 'Morgan_235', 'Morgan_236', 'Morgan_238', 'Morgan_240', 'Morgan_242', 'Morgan_244', 'Morgan_245', 'Morgan_250', 'Morgan_251', 'Morgan_254', 'Morgan_258', 'Morgan_260', 'Morgan_261', 'Morgan_262', 'Morgan_266', 'Morgan_267', 'Morgan_270', 'Morgan_272', 'Morgan_273', 'Morgan_274', 'Morgan_275', 'Morgan_276', 'Morgan_277', 'Morgan_278', 'Morgan_280', 'Morgan_282', 'Morgan_285', 'Morgan_286', 'Morgan_290', 'Morgan_291', 'Morgan_293', 'Morgan_295', 'Morgan_297', 'Morgan_299', 'Morgan_300', 'Morgan_301', 'Morgan_302', 'Morgan_306', 'Morgan_307', 'Morgan_308', 'Morgan_310', 'Morgan_311', 'Morgan_312', 'Morgan_314', 'Morgan_318', 'Morgan_319', 'Morgan_320', 'Morgan_321', 'Morgan_322', 'Morgan_323', 'Morgan_324', 'Morgan_326', 'Morgan_331', 'Morgan_334', 'Morgan_335', 'Morgan_336', 'Morgan_341', 'Morgan_346', 'Morgan_347', 'Morgan_350', 'Morgan_352', 'Morgan_353', 'Morgan_354', 'Morgan_356', 'Morgan_358', 'Morgan_362', 'Morgan_363', 'Morgan_366', 'Morgan_367', 'Morgan_370', 'Morgan_373', 'Morgan_374', 'Morgan_376', 'Morgan_377', 'Morgan_379', 'Morgan_380', 'Morgan_381', 'Morgan_383', 'Morgan_384', 'Morgan_386', 'Morgan_394', 'Morgan_397', 'Morgan_398', 'Morgan_399', 'Morgan_405', 'Morgan_407', 'Morgan_409', 'Morgan_415', 'Morgan_416', 'Morgan_418', 'Morgan_419', 'Morgan_421', 'Morgan_423', 'Morgan_425', 'Morgan_427', 'Morgan_428', 'Morgan_430', 'Morgan_431', 'Morgan_432', 'Morgan_435', 'Morgan_437', 'Morgan_438', 'Morgan_440', 'Morgan_442', 'Morgan_443', 'Morgan_444', 'Morgan_445', 'Morgan_446', 'Morgan_448', 'Morgan_451', 'Morgan_454', 'Morgan_455', 'Morgan_456', 'Morgan_457', 'Morgan_460', 'Morgan_462', 'Morgan_466', 'Morgan_470', 'Morgan_472', 'Morgan_473', 'Morgan_477', 'Morgan_478', 'Morgan_480', 'Morgan_482', 'Morgan_487', 'Morgan_488', 'Morgan_489', 'Morgan_492', 'Morgan_493', 'Morgan_496', 'Morgan_497', 'Morgan_502', 'Morgan_503', 'Morgan_508', 'Morgan_509', 'Morgan_510', 'Morgan_511', 'MACCS_3', 'MACCS_5', 'MACCS_6', 'MACCS_7', 'MACCS_9', 'MACCS_12', 'MACCS_15', 'MACCS_16', 'MACCS_18', 'MACCS_19', 'MACCS_20', 'MACCS_21', 'MACCS_23', 'MACCS_26', 'MACCS_27', 'MACCS_28', 'MACCS_30', 'MACCS_31', 'MACCS_34', 'MACCS_36', 'MACCS_38', 'MACCS_39', 'MACCS_41', 'MACCS_43', 'MACCS_44', 'MACCS_46', 'MACCS_48', 'MACCS_49', 'MACCS_52', 'MACCS_53', 'MACCS_54', 'MACCS_58', 'MACCS_59', 'MACCS_60', 'MACCS_61', 'MACCS_62', 'MACCS_63', 'MACCS_64', 'MACCS_66', 'MACCS_67', 'MACCS_69', 'MACCS_71', 'MACCS_72', 'MACCS_73', 'MACCS_74', 'MACCS_75', 'MACCS_76', 'MACCS_77', 'MACCS_78', 'MACCS_79', 'MACCS_80', 'MACCS_84', 'MACCS_85', 'MACCS_87', 'MACCS_88', 'MACCS_89', 'MACCS_92', 'MACCS_94', 'MACCS_95', 'MACCS_98', 'MACCS_100', 'MACCS_102', 'MACCS_109', 'MACCS_111', 'MACCS_112', 'MACCS_114', 'MACCS_116', 'MACCS_117', 'MACCS_118', 'MACCS_119', 'MACCS_120', 'MACCS_121', 'MACCS_122', 'MACCS_123', 'MACCS_124', 'MACCS_126', 'MACCS_128', 'MACCS_130', 'MACCS_132', 'MACCS_133', 'MACCS_135', 'MACCS_142', 'MACCS_145', 'MACCS_146', 'MACCS_150', 'MACCS_151', 'MACCS_152', 'MACCS_156', 'MACCS_160', 'MACCS_161', 'MACCS_164', 'MACCS_165', 'SMR_VSA_sum', 'Gasteiger_q_sum', 'Gasteiger_q_min', 'Gasteiger_q_max', 'Gasteiger_q_std', 'HBondCapacity', 'HBondDensity_perHeavyAtom', 'RingDensity_perHeavyAtom', 'LogP_div_TPSA', 'LogP_x_TPSA', 'Flexibility_Score', 'MolWt_x_AromaticRings', 'Complexity_per_MW', 'Rigidity_Score', 'FracSingle', 'FracDouble', 'FracTriple', 'MeanBondOrder', 'Rings5', 'Rings7', 'Rings8', 'RingSystems', 'Rings56_frac', 'MurckoAtoms', 'FormalCharge', 'IsZwitterion', 'SMI_len', 'SMI_branches', 'SMI_ringDigits', 'SMI_stereoAt', 'SMI_ezSlashes']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['result/ga_features.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "import time\n",
    "from sklearn_genetic import GAFeatureSelectionCV\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"\\n--- üß¨ START RUN GENETIC ALGORITHM ---\")\n",
    "start = time.time()\n",
    "model = LGBMRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=31,\n",
    "    max_depth=-1,\n",
    "    random_state=2601,\n",
    "    n_jobs=1, verbose=-1\n",
    "    )\n",
    "\n",
    "ga = GAFeatureSelectionCV(\n",
    "    estimator=model,\n",
    "    cv=3,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    population_size=50,    \n",
    "    generations=15,\n",
    "    mutation_probability=0.1,\n",
    "    crossover_probability=0.8,\n",
    "    keep_top_k=2,\n",
    "    elitism=True,\n",
    "    n_jobs=-1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "ga.fit(X_train, y_train)\n",
    "\n",
    "selected_ga = X_train.columns[ga.support_]\n",
    "\n",
    "print(f\"‚è±Ô∏è Time Run: {time.time() - start:.2f} s\")\n",
    "print(f\"\\n‚úÖ GA Choosen {len(selected_ga)} features:\")\n",
    "print(\"\\List Features:\")\n",
    "print(list(selected_ga))\n",
    "\n",
    "import joblib\n",
    "joblib.dump(list(selected_ga), 'result/ga_features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586459f5",
   "metadata": {},
   "source": [
    "# UNION 2 MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caa5a74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíé T·ªïng features sau khi g·ªôp (Union): 632\n",
      "['NumHDonors', 'Count_C', 'MACCS_94', 'fr_para_hydroxylation', 'Morgan_117', 'Morgan_157', 'Morgan_260', 'FracSingle', 'Morgan_440', 'MACCS_67', 'MaxPartialCharge', 'Morgan_397', 'MACCS_3', 'Morgan_189', 'HeavyAtomMolWt', 'fr_dihydropyridine', 'MACCS_23', 'MACCS_144', 'Morgan_250', 'Morgan_482', 'SMI_len', 'Morgan_233', 'Morgan_217', 'Morgan_415', 'fr_allylic_oxid', 'fr_NH1', 'Rings56_frac', 'Morgan_376', 'Morgan_416', 'Morgan_323', 'Morgan_509', 'Morgan_321', 'Morgan_443', 'SMI_ringDigits', 'MinPartialCharge', 'Morgan_421', 'NHOHCount', 'Morgan_134', 'Morgan_64', 'PEOE_VSA13', 'Morgan_267', 'Gasteiger_q_abs_sum', 'Morgan_377', 'MACCS_121', 'NumRadicalElectrons', 'MACCS_164', 'MACCS_106', 'Chi2v', 'MACCS_59', 'PEOE_VSA3', 'MACCS_15', 'SlogP_VSA1', 'RingDensity_perHeavyAtom', 'Morgan_124', 'MACCS_53', 'MACCS_150', 'Morgan_192', 'SlogP_VSA0', 'Morgan_68', 'Morgan_135', 'Morgan_493', 'Morgan_438', 'Morgan_394', 'RingCount', 'Morgan_1', 'Morgan_427', 'Morgan_310', 'Morgan_27', 'Morgan_332', 'EState_VSA1', 'Morgan_492', 'Morgan_386', 'Morgan_319', 'Morgan_90', 'Morgan_151', 'Morgan_345', 'Rings6', 'fr_NH0', 'Morgan_177', 'BCUT2D_LOGPHI', 'Morgan_154', 'Morgan_119', 'Morgan_52', 'fr_unbrch_alkane', 'Morgan_399', 'MACCS_132', 'BertzCT', 'MACCS_130', 'fr_furan', 'Morgan_361', 'fr_N_O', 'MACCS_38', 'BCUT2D_MRHI', 'MACCS_153', 'Morgan_307', 'NumHeteroatoms', 'Morgan_336', 'Morgan_44', 'MACCS_41', 'fr_imidazole', 'Morgan_216', 'fr_Al_COO', 'Morgan_341', 'Morgan_13', 'Morgan_270', 'MACCS_92', 'Morgan_76', 'Morgan_374', 'Morgan_445', 'MACCS_16', 'Rings7', 'BalabanJ', 'Morgan_488', 'MACCS_83', 'fr_guanido', 'Morgan_405', 'Morgan_274', 'Morgan_81', 'Morgan_299', 'Chi4v', 'Morgan_58', 'Chi1', 'Morgan_278', 'qed', 'Morgan_48', 'MolLogP', 'Morgan_153', 'Morgan_293', 'Morgan_88', 'MACCS_89', 'PEOE_VSA10', 'Count_P', 'MACCS_75', 'NumAromaticCarbocycles', 'Chi4n', 'MACCS_5', 'Morgan_435', 'FracAromatic', 'MACCS_12', 'Count_N', 'Morgan_56', 'VSA_EState1', 'MACCS_90', 'Morgan_308', 'Morgan_290', 'FormalCharge', 'Morgan_428', 'fr_piperdine', 'fr_nitro', 'MACCS_78', 'MACCS_135', 'Morgan_466', 'NumValenceElectrons', 'Morgan_354', 'Morgan_163', 'MinAbsEStateIndex', 'Morgan_444', 'Morgan_69', 'MACCS_28', 'Chi1v', 'VSA_EState9', 'MACCS_48', 'Morgan_244', 'Morgan_93', 'MACCS_118', 'Morgan_73', 'Morgan_6', 'Morgan_144', 'PEOE_VSA14', 'Morgan_286', 'Morgan_407', 'Morgan_470', 'Morgan_480', 'Morgan_344', 'AromRingFrac', 'SMR_VSA10', 'Morgan_457', 'Morgan_234', 'Morgan_89', 'MolWt_x_AromaticRings', 'Morgan_211', 'MACCS_160', 'Morgan_149', 'SMI_branches', 'MACCS_71', 'Morgan_131', 'Morgan_353', 'MACCS_49', 'MACCS_47', 'Morgan_84', 'Morgan_145', 'EState_VSA9', 'Chi0n', 'fr_C_O_noCOO', 'Morgan_342', 'Morgan_109', 'Morgan_138', 'Rigidity_Score', 'FpDensityMorgan3', 'Count_H', 'NumAromaticRings', 'Morgan_78', 'Morgan_446', 'Morgan_380', 'Morgan_28', 'Morgan_96', 'Morgan_502', 'Morgan_258', 'Morgan_99', 'MACCS_85', 'SMR_VSA1', 'Morgan_101', 'Morgan_261', 'Morgan_152', 'fr_lactam', 'Morgan_201', 'MACCS_120', 'MACCS_117', 'Morgan_423', 'LogP_x_TPSA', 'EState_VSA10', 'SMR_VSA4', 'Chi0v', 'MACCS_155', 'Morgan_104', 'SMI_ezSlashes', 'Morgan_311', 'Morgan_383', 'Morgan_478', 'EState_VSA8', 'NumBridgeheadAtoms', 'fr_aldehyde', 'MACCS_112', 'NumHeterocycles', 'Morgan_384', 'Morgan_79', 'Morgan_2', 'fr_thiophene', 'Morgan_398', 'MeanBondOrder', 'MACCS_146', 'NOCount', 'Morgan_272', 'MaxAbsEStateIndex', 'Morgan_174', 'Morgan_169', 'MACCS_152', 'Count_Cl', 'EState_VSA3', 'fr_Al_OH_noTert', 'NumUnspecifiedAtomStereoCenters', 'Morgan_367', 'MACCS_52', 'Morgan_362', 'Morgan_370', 'HBondDensity_perHeavyAtom', 'Morgan_98', 'Morgan_335', 'SlogP_VSA3', 'HBondCapacity', 'SMR_VSA8', 'Gasteiger_q_std', 'HeteroAtomFrac', 'MACCS_142', 'Morgan_306', 'fr_barbitur', 'Morgan_275', 'SlogP_VSA11', 'MACCS_46', 'MACCS_88', 'EState_VSA5', 'fr_Ar_COO', 'Morgan_491', 'Morgan_437', 'VSA_EState3', 'Morgan_462', 'Morgan_363', 'MACCS_122', 'Flexibility_Score', 'PEOE_VSA4', 'Morgan_37', 'Morgan_25', 'Morgan_15', 'MACCS_126', 'fr_Imine', 'NumSpiroAtoms', 'Count_S', 'Morgan_158', 'Morgan_72', 'HallKierAlpha', 'MACCS_105', 'fr_Al_OH', 'Morgan_282', 'Morgan_214', 'Chi3n', 'Gasteiger_q_sum', 'Morgan_364', 'Morgan_102', 'Morgan_497', 'Morgan_95', 'Morgan_127', 'Morgan_175', 'MACCS_133', 'Morgan_16', 'Morgan_97', 'Morgan_38', 'Morgan_245', 'PEOE_VSA5', 'Morgan_80', 'Morgan_137', 'HeavyAtomCount', 'Morgan_39', 'Morgan_121', 'fr_isocyan', 'fr_Ar_N', 'Morgan_161', 'NumRotatableBonds', 'Morgan_324', 'SlogP_VSA7', 'MACCS_119', 'BCUT2D_MWLOW', 'NumSaturatedHeterocycles', 'Morgan_164', 'LargestRingSize', 'PEOE_VSA7', 'MinEStateIndex', 'Morgan_448', 'MACCS_149', 'Morgan_401', 'MACCS_72', 'Morgan_143', 'MACCS_60', 'MinAbsPartialCharge', 'Morgan_156', 'Morgan_24', 'EState_VSA6', 'Morgan_511', 'Morgan_31', 'Morgan_425', 'VSA_EState4', 'Morgan_238', 'Morgan_346', 'Morgan_430', 'MACCS_9', 'Morgan_254', 'fr_hdrzone', 'LabuteASA', 'MolWt', 'Morgan_326', 'PEOE_VSA8', 'Morgan_460', 'MACCS_69', 'Morgan_53', 'fr_COO2', 'Morgan_85', 'MACCS_98', 'Morgan_8', 'PEOE_VSA9', 'fr_C_S', 'fr_halogen', 'MACCS_66', 'fr_ether', 'MACCS_77', 'Morgan_442', 'fr_lactone', 'MACCS_7', 'Morgan_496', 'Morgan_503', 'BCUT2D_CHGHI', 'FracTriple', 'Morgan_11', 'MACCS_58', 'Morgan_30', 'Morgan_235', 'Morgan_291', 'Morgan_313', 'NumHAcceptors', 'SlogP_VSA2', 'MACCS_151', 'MACCS_63', 'Morgan_183', 'MACCS_114', 'Morgan_451', 'MACCS_18', 'SMR_VSA5', 'Morgan_146', 'MolMR', 'NumAmideBonds', 'fr_ester', 'Morgan_194', 'MACCS_156', 'Morgan_208', 'Morgan_300', 'Morgan_277', 'Morgan_33', 'fr_oxazole', 'Morgan_276', 'MaxEStateIndex', 'Morgan_400', 'Morgan_487', 'Morgan_91', 'VSA_EState8', 'Morgan_431', 'SMI_stereoAt', 'MACCS_31', 'Morgan_294', 'Morgan_368', 'EState_VSA4', 'Gasteiger_q_max', 'Morgan_273', 'Morgan_21', 'Morgan_494', 'Morgan_453', 'Morgan_182', 'fr_morpholine', 'Morgan_455', 'Morgan_301', 'MACCS_79', 'MACCS_100', 'IsZwitterion', 'MACCS_19', 'Morgan_381', 'FpDensityMorgan2', 'PEOE_VSA12', 'FracDouble', 'UnsatBondCount', 'Morgan_322', 'Morgan_352', 'Morgan_356', 'SlogP_VSA4', 'fr_quatN', 'Morgan_508', 'Chi0', 'Rings5', 'EState_VSA7', 'fr_Ndealkylation2', 'Morgan_77', 'Morgan_302', 'Morgan_320', 'NumAtomStereoCenters', 'NumSaturatedRings', 'fr_Ar_OH', 'HBond_Product', 'Morgan_148', 'Rings8', 'Kappa2', 'Morgan_22', 'MACCS_109', 'MurckoAtoms', 'Morgan_29', 'Morgan_184', 'SPS', 'Morgan_113', 'Morgan_17', 'fr_Ar_NH', 'Morgan_200', 'Phi', 'MACCS_74', 'RingSystems', 'fr_phenol', 'MACCS_102', 'MACCS_44', 'Morgan_419', 'MACCS_43', 'MACCS_128', 'fr_azo', 'Morgan_366', 'Morgan_86', 'PEOE_VSA1', 'Morgan_103', 'MACCS_26', 'Morgan_295', 'Complexity_per_MW', 'fr_isothiocyan', 'FractionCSP3', 'fr_benzodiazepine', 'fr_imide', 'Morgan_358', 'MACCS_124', 'Morgan_489', 'SMR_VSA_sum', 'Morgan_125', 'Morgan_236', 'BCUT2D_MRLOW', 'Morgan_220', 'Morgan_297', 'Morgan_173', 'FpDensityMorgan1', 'MACCS_107', 'Morgan_120', 'fr_NH2', 'fr_aryl_methyl', 'fr_ketone_Topliss', 'SMR_VSA6', 'fr_thiazole', 'Morgan_314', 'MACCS_62', 'MACCS_95', 'MACCS_101', 'MACCS_84', 'Morgan_318', 'BCUT2D_LOGPLOW', 'Morgan_472', 'Morgan_266', 'Morgan_193', 'Morgan_23', 'fr_ketone', 'fr_COO', 'Morgan_379', 'MACCS_127', 'fr_amidine', 'Morgan_132', 'EState_VSA2', 'Morgan_510', 'Morgan_100', 'fr_phenol_noOrthoHbond', 'MACCS_145', 'Morgan_251', 'Morgan_454', 'PEOE_VSA2', 'VSA_EState5', 'fr_phos_ester', 'Morgan_312', 'Count_O', 'fr_nitro_arom', 'Ipc', 'Morgan_418', 'Morgan_70', 'Morgan_331', 'MACCS_36', 'MACCS_123', 'Morgan_479', 'Morgan_473', 'MACCS_39', 'Morgan_36', 'Morgan_347', 'SideChainAtoms', 'Morgan_57', 'TPSA', 'Morgan_165', 'Morgan_45', 'fr_thiocyan', 'SMR_VSA0', 'ExactMolWt', 'fr_HOCCN', 'Morgan_147', 'Morgan_350', 'MACCS_30', 'fr_tetrazole', 'MACCS_34', 'MACCS_54', 'MaxAbsPartialCharge', 'Morgan_26', 'Morgan_373', 'SlogP_VSA9', 'MACCS_20', 'NumAliphaticHeterocycles', 'MACCS_131', 'Count_F', 'SMR_VSA3', 'SlogP_VSA_sum', 'MACCS_80', 'Morgan_240', 'MACCS_24', 'Morgan_3', 'MACCS_111', 'PEOE_VSA11', 'Kappa1', 'VSA_EState10', 'Morgan_242', 'Morgan_408', 'MACCS_6', 'NumAliphaticRings', 'Morgan_130', 'Morgan_432', 'BCUT2D_CHGLO', 'Morgan_232', 'SlogP_VSA5', 'Morgan_49', 'MACCS_73', 'Morgan_172', 'Morgan_280', 'Morgan_54', 'PEOE_VSA6', 'MACCS_165', 'Morgan_50', 'Chi2n', 'Morgan_176', 'fr_bicyclic', 'LogP_div_TPSA', 'Gasteiger_q_min', 'MACCS_21', 'MACCS_61', 'Morgan_65', 'VSA_EState7', 'MACCS_87', 'MACCS_64', 'Morgan_205', 'MACCS_76', 'Morgan_43', 'BCUT2D_MWHI', 'AvgIpc', 'Morgan_181', 'EState_VSA11', 'Morgan_190', 'MACCS_27', 'MACCS_116', 'VSA_EState6', 'Chi1n', 'Morgan_334', 'Morgan_378', 'Morgan_204', 'Morgan_35', 'Chi3v', 'Morgan_477', 'Morgan_107', 'Morgan_409', 'Morgan_456', 'Morgan_7', 'Morgan_166', 'Morgan_186', 'Morgan_34', 'Morgan_262', 'Morgan_133', 'Morgan_283', 'Morgan_285', 'SMR_VSA2', 'Kappa3', 'MACCS_161', 'fr_pyridine', 'VSA_EState2', 'Morgan_92']\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "rfe_features = joblib.load('result/rfe_features.pkl')\n",
    "ga_features = joblib.load('result/ga_features.pkl')\n",
    "\n",
    "common_features = set(rfe_features) | set(ga_features)\n",
    "\n",
    "print(f\"\\nüíé T·ªïng features sau khi g·ªôp (Union): {len(common_features)}\")\n",
    "print(list(common_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878057cb",
   "metadata": {},
   "source": [
    "# CHOICE BEST FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa9d839a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒêang train model cu·ªëi c√πng v·ªõi 297 features...\n",
      "üíæ ƒê√£ l∆∞u model v√† features th√†nh c√¥ng!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "best_features = list(rfe_features)\n",
    "\n",
    "print(f\"‚úÖ ƒêang train model cu·ªëi c√πng v·ªõi {len(best_features)} features...\")\n",
    "\n",
    "manual_params = {\n",
    "    'n_estimators': 3000,\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 60,\n",
    "    'max_depth': 15,\n",
    "    'objective': 'regression_l1',\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'random_state': 2601,\n",
    "    'n_jobs': 1,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "final_model = LGBMRegressor(**manual_params)\n",
    "\n",
    "final_model.fit(X_clean[best_features], y)\n",
    "\n",
    "# L∆∞u model v√† danh s√°ch features\n",
    "joblib.dump(final_model, 'result/final_melting_point_model.pkl')\n",
    "joblib.dump(best_features, 'result/final_features_list.pkl')\n",
    "\n",
    "print(\"üíæ ƒê√£ l∆∞u model v√† features th√†nh c√¥ng!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dc7df6",
   "metadata": {},
   "source": [
    "# SCORING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c831c1d",
   "metadata": {},
   "source": [
    "## Score Combine Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7549c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è(Imputing)...\n",
      "\n",
      "--- üèÅ RESULT ---\n",
      "MAE: 76.1625\n",
      "RMSE: 279.5836\n",
      "R2: 0.5021\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import gc\n",
    "model = joblib.load('result/final_melting_point_model.pkl')\n",
    "features = joblib.load('result/final_features_list.pkl')\n",
    "\n",
    "df = pd.read_csv('result/data/melting_point_features.csv')\n",
    "\n",
    "needed_cols = list(features) + ['Tm']\n",
    "\n",
    "existing_cols = [c for c in needed_cols if c in df.columns]\n",
    "\n",
    "df_reduced = df[existing_cols].copy()\n",
    "\n",
    "del df\n",
    "gc.collect()\n",
    "\n",
    "y = df_reduced['Tm']\n",
    "X = df_reduced.drop(columns=['Tm'])\n",
    "\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X = X.mask(X > 1e308, np.nan)\n",
    "\n",
    "print(\"‚öôÔ∏è(Imputing)...\")\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_clean = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "_, X_test, _, y_test = train_test_split(X_clean, y, test_size=0.2, random_state=2601)\n",
    "\n",
    "y_pred = model.predict(X_test[features])\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n--- üèÅ RESULT ---\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R2: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b8109b",
   "metadata": {},
   "source": [
    "## Score each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95c2314e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Method  Features      RMSE      R2  Diff_RMSE  Diff_R2\n",
      "0  Original       937  249.9172  0.6190     0.0000   0.0000\n",
      "1       RFE         0    0.0000  0.0000  -249.9172  -0.6190\n",
      "2        GA       494  251.0353  0.6155     1.1180  -0.0034\n",
      "\n",
      "Common Features (0): []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('result/data/melting_point_features.csv')\n",
    "y = df['Tm']\n",
    "X = df.drop(columns=['Tm']).select_dtypes(include=[np.number])\n",
    "\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X = X.mask(X > 1e308, np.nan)\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_clean = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_clean, y, test_size=0.2)\n",
    "\n",
    "def get_metrics(name, feature_list):\n",
    "    valid_feats = [f for f in feature_list if f in X_train.columns]\n",
    "    \n",
    "    if not valid_feats: return {\"Method\": name, \"Features\": 0, \"RMSE\": 0, \"R2\": 0}\n",
    "\n",
    "    model = LGBMRegressor(      \n",
    "        n_jobs=1,\n",
    "        verbose=-1,\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.01,\n",
    "        num_leaves=50,\n",
    "        max_depth=-1)\n",
    "    model.fit(X_train[valid_feats], y_train)\n",
    "    y_pred = model.predict(X_test[valid_feats])\n",
    "    \n",
    "    return {\n",
    "        \"Method\": name,\n",
    "        \"Features\": len(valid_feats),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        \"R2\": r2_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "feats_all = list(X_train.columns)\n",
    "feats_rfe = list(selected_rfe) if 'selected_rfe' in globals() else []\n",
    "feats_ga = list(selected_ga) if 'selected_ga' in globals() else []\n",
    "\n",
    "results = []\n",
    "results.append(get_metrics(\"Original\", feats_all))\n",
    "results.append(get_metrics(\"RFE\", feats_rfe))\n",
    "results.append(get_metrics(\"GA\", feats_ga))\n",
    "\n",
    "df_res = pd.DataFrame(results)\n",
    "base_rmse = df_res.loc[0, 'RMSE']\n",
    "base_r2 = df_res.loc[0, 'R2']\n",
    "\n",
    "df_res['Diff_RMSE'] = df_res['RMSE'] - base_rmse\n",
    "df_res['Diff_R2'] = df_res['R2'] - base_r2\n",
    "\n",
    "print(df_res.round(4))\n",
    "\n",
    "common = set(feats_rfe) & set(feats_ga)\n",
    "print(f\"\\nCommon Features ({len(common)}):\", list(common))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736270fd",
   "metadata": {},
   "source": [
    "# GridSearch Find Best Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e60922e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... GridSearch ...\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m valid_ga_feats = [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(selected_ga) \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m X_train.columns]\n\u001b[32m     16\u001b[39m grid = GridSearchCV(base_model, param_grid, cv=\u001b[32m3\u001b[39m, scoring=\u001b[33m'\u001b[39m\u001b[33mr2\u001b[39m\u001b[33m'\u001b[39m, n_jobs=\u001b[32m4\u001b[39m, verbose=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mgrid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalid_ga_feats\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Best Params ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest Params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid.best_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"... GridSearch ...\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [500, 1000, 2000],\n",
    "    'learning_rate': [0.01, 0.03, 0.05],\n",
    "    'num_leaves': [31, 50],\n",
    "    'max_depth': [-1, 10, 20]\n",
    "}\n",
    "\n",
    "base_model = LGBMRegressor(n_jobs=1, verbose=-1)\n",
    "\n",
    "valid_ga_feats = [f for f in list(selected_ga) if f in X_train.columns]\n",
    "\n",
    "grid = GridSearchCV(base_model, param_grid, cv=3, scoring='r2', n_jobs=4, verbose=1)\n",
    "grid.fit(X_train[valid_ga_feats], y_train)\n",
    "\n",
    "print(\"\\n--- Best Params ---\")\n",
    "print(f\"Best Params: {grid.best_params_}\")\n",
    "print(f\"Best R2 Score (Train CV): {grid.best_score_:.4f}\")\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test[valid_ga_feats])\n",
    "print(f\"Test R2 Score: {r2_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d25ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "model_final = LGBMRegressor(\n",
    "    learning_rate=0.01, \n",
    "    n_estimators=500, \n",
    "    num_leaves=50, \n",
    "    max_depth=-1, \n",
    "    random_state=2601, \n",
    "    n_jobs=1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=2601)\n",
    "\n",
    "valid_ga_feats = [f for f in list(selected_ga) if f in X_train.columns]\n",
    "X_ga = X_clean[valid_ga_feats]\n",
    "\n",
    "scores = cross_val_score(model_final, X_ga, y, cv=kf, scoring='r2', n_jobs=4)\n",
    "\n",
    "print(f\"Scores: {scores}\")\n",
    "print(f\"Mean R2: {scores.mean():.4f} (+/- {scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e709c9b7",
   "metadata": {},
   "source": [
    "# Elbow GA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098e2a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "best_params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'n_estimators': 2000,\n",
    "    'num_leaves': 50,\n",
    "    'max_depth': -1,\n",
    "    'random_state': 2601,\n",
    "    'n_jobs': 1,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "valid_ga_feats = [f for f in list(selected_ga) if f in X_train.columns]\n",
    "\n",
    "print(\"ƒêang x·∫øp h·∫°ng features...\")\n",
    "ranker = LGBMRegressor(**best_params)\n",
    "ranker.fit(X_train[valid_ga_feats], y_train)\n",
    "\n",
    "imp_df = pd.DataFrame({\n",
    "    'Feature': valid_ga_feats,\n",
    "    'Importance': ranker.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "sorted_feats = imp_df['Feature'].tolist()\n",
    "\n",
    "steps = list(range(len(sorted_feats), 99, -50)) + list(range(90, 0, -10))\n",
    "results = []\n",
    "\n",
    "print(f\"\\nB·∫Øt ƒë·∫ßu v√≤ng l·∫∑p c·∫Øt gi·∫£m features ({len(steps)} v√≤ng)...\")\n",
    "\n",
    "for k in steps:\n",
    "    current_feats = sorted_feats[:k]\n",
    "    \n",
    "    model = LGBMRegressor(**best_params)\n",
    "    model.fit(X_train[current_feats], y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test[current_feats])\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    print(f\"   -> D√πng {k:3d} features: R2 = {r2:.4f} | RMSE = {rmse:.2f}\")\n",
    "    results.append({'Num_Features': k, 'R2': r2, 'RMSE': rmse})\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(results).sort_values(by='Num_Features')\n",
    "df_leaderboard = df_results.sort_values(by='R2', ascending=False).reset_index(drop=True)\n",
    "csv_filename = 'result/feature_selection_results.csv'\n",
    "df_results.to_csv(csv_filename, index=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_results['Num_Features'], df_results['R2'], marker='o', linewidth=2, color='blue')\n",
    "\n",
    "best_row = df_results.loc[df_results['R2'].idxmax()]\n",
    "plt.scatter(best_row['Num_Features'], best_row['R2'], color='red', s=150, zorder=5)\n",
    "plt.annotate(f\"ƒê·ªânh: {best_row['R2']:.4f}\\n({int(best_row['Num_Features'])} feats)\", \n",
    "             (best_row['Num_Features'], best_row['R2']), \n",
    "             xytext=(best_row['Num_Features']+20, best_row['R2']-0.01),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "\n",
    "plt.title('Bi·ªÉu ƒë·ªì Elbow: Hi·ªáu qu·∫£ khi gi·∫£m d·∫ßn s·ªë l∆∞·ª£ng Features', fontsize=14)\n",
    "plt.xlabel('S·ªë l∆∞·ª£ng Features', fontsize=12)\n",
    "plt.ylabel('ƒê·ªô ch√≠nh x√°c (R2)', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nB·∫¢NG X·∫æP H·∫†NG (SCORE GI·∫¢M D·∫¶N):\")\n",
    "print(df_leaderboard[['R2', 'Num_Features', 'RMSE']].head(10))\n",
    "\n",
    "print(\"\\nB·∫¢NG THEO TH·ª® T·ª∞ FEATURE (√çT -> NHI·ªÄU):\")\n",
    "print(df_results[['Num_Features', 'R2', 'RMSE']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e13a8c2",
   "metadata": {},
   "source": [
    "# Elbow RFECV Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ae099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n--- START RFE WITH LEADERBOARD ---\")\n",
    "start = time.time()\n",
    "\n",
    "model = LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.01,\n",
    "    num_leaves=50,\n",
    "    max_depth=-1,\n",
    "    random_state=2601,\n",
    "    n_jobs=1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "rfecv = RFECV(\n",
    "    estimator=model,\n",
    "    step=20,\n",
    "    cv=3,\n",
    "    scoring='r2', \n",
    "    min_features_to_select=50,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "r2_scores = rfecv.cv_results_['mean_test_score']\n",
    "n_scores = len(r2_scores)\n",
    "\n",
    "feature_counts = [50 + i * 20 for i in range(n_scores)]\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'Num_Features': feature_counts,\n",
    "    'Score_R2': r2_scores\n",
    "})\n",
    "\n",
    "df_leaderboard = df_results.sort_values(by='Score_R2', ascending=False).reset_index(drop=True)\n",
    "\n",
    "selected_rfecv = X_train.columns[rfecv.support_]\n",
    "print(f\"\\nTime Run: {time.time() - start:.2f} s\")\n",
    "print(f\"Best Number of Features: {rfecv.n_features_}\")\n",
    "print(f\"Best R2 Score: {df_leaderboard.iloc[0]['Score_R2']:.4f}\")\n",
    "\n",
    "print(\"\\nLEADERBOARD (DESCENDING SCORE):\")\n",
    "print(df_leaderboard.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nPROGRESS (BY FEATURE COUNT):\")\n",
    "print(df_results.head(10).to_string(index=False))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_results['Num_Features'], df_results['Score_R2'], marker='o', color='green', linewidth=2)\n",
    "\n",
    "best_row = df_leaderboard.iloc[0]\n",
    "plt.scatter(best_row['Num_Features'], best_row['Score_R2'], color='red', s=150, zorder=5)\n",
    "plt.annotate(f\"Best: {best_row['Score_R2']:.4f}\\n({int(best_row['Num_Features'])} feats)\", \n",
    "             (best_row['Num_Features'], best_row['Score_R2']), \n",
    "             xytext=(best_row['Num_Features']+20, best_row['Score_R2']-0.005),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "\n",
    "plt.title('RFECV Performance Curve', fontsize=14)\n",
    "plt.xlabel('Number of Features Selected', fontsize=12)\n",
    "plt.ylabel('Cross Validation Score (R2)', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSelected Features List:\")\n",
    "print(list(selected_rfecv))\n",
    "\n",
    "df_results.to_csv('result/rfecv_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5728a31e",
   "metadata": {},
   "source": [
    "# Compare before and after using partial correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257cc2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "ULTRA_HIGH_CORR = 0.999 \n",
    "\n",
    "corr_matrix = X_train_clean.corr().abs()\n",
    "\n",
    "ranker_temp = LGBMRegressor(n_estimators=100, verbose=-1, random_state=2601)\n",
    "ranker_temp.fit(X_train_clean, y_train_clean)\n",
    "importances = pd.Series(ranker_temp.feature_importances_, index=X_train_clean.columns)\n",
    "\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = []\n",
    "\n",
    "for column in upper.columns:\n",
    "    correlated_cols = upper.index[upper[column] > ULTRA_HIGH_CORR].tolist()\n",
    "    if correlated_cols:\n",
    "        for other_col in correlated_cols:\n",
    "            if other_col in to_drop: continue\n",
    "            imp_col = importances.get(column, 0)\n",
    "            imp_other = importances.get(other_col, 0)\n",
    "            if imp_col < imp_other:\n",
    "                to_drop.append(column)\n",
    "                break \n",
    "            else:\n",
    "                to_drop.append(other_col)\n",
    "\n",
    "to_drop = list(set(to_drop))\n",
    "\n",
    "print(f\"Phat hien {len(to_drop)} features tuong quan > {ULTRA_HIGH_CORR}\")\n",
    "print(f\"Vi du: {to_drop[:5]}\")\n",
    "\n",
    "voting_model = LGBMRegressor(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=2000,\n",
    "    num_leaves=50,\n",
    "    max_depth=-1,\n",
    "    random_state=2601,\n",
    "    n_jobs=1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "if len(to_drop) > 0:\n",
    "    X_train_ultra = X_train_clean.drop(columns=to_drop)\n",
    "    X_test_ultra = X_test.drop(columns=to_drop)\n",
    "\n",
    "    print(f\"Train thu tren {X_train_ultra.shape[1]} features...\")\n",
    "    voting_model.fit(X_train_ultra, y_train_clean)\n",
    "    \n",
    "    y_pred = voting_model.predict(X_test_ultra)\n",
    "    new_r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    old_r2 = 0.6313 \n",
    "    \n",
    "    print(f\"Ket qua R2 moi: {new_r2:.4f}\")\n",
    "    \n",
    "    methods = ['Original Clean', 'Filtered (>0.995)']\n",
    "    scores = [old_r2, new_r2]\n",
    "    colors = ['green', 'red']\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    bars = plt.bar(methods, scores, color=colors, width=0.5)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                 f'{height:.4f}',\n",
    "                 ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "    plt.title('Hieu qua giua giu nguyen va loc tuong quan', fontsize=14)\n",
    "    plt.ylabel('R2 Score', fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.ylim(0, 0.8)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Khong co features nao qua giong nhau de xoa.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b8e1ac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a24c7",
   "metadata": {},
   "source": [
    "# EXTRA MODEL \n",
    "# MAE (Mean Absolute Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0985c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "import time\n",
    "\n",
    "best_params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'n_estimators': 2000,\n",
    "    'num_leaves': 50,\n",
    "    'max_depth': -1,\n",
    "    'random_state': 2601,\n",
    "    'n_jobs': 1,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "fast_params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 100,\n",
    "    'num_leaves': 31,\n",
    "    'random_state': 2601,\n",
    "    'n_jobs': -1,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "print(\"Ranking features (Fast Mode)...\")\n",
    "start_time = time.time()\n",
    "\n",
    "rfe_selector = RFE(estimator=LGBMRegressor(**fast_params), \n",
    "                   n_features_to_select=1, \n",
    "                   step=0.1, \n",
    "                   verbose=0)\n",
    "\n",
    "rfe_selector.fit(X_train, y_train) \n",
    "\n",
    "rfe_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Rank': rfe_selector.ranking_\n",
    "}).sort_values(by='Rank', ascending=True)\n",
    "\n",
    "sorted_feats = rfe_df['Feature'].tolist()\n",
    "print(f\"Ranking done in {time.time() - start_time:.1f}s\")\n",
    "\n",
    "steps = list(range(len(sorted_feats), 99, -50)) + list(range(90, 0, -10))\n",
    "results = []\n",
    "\n",
    "print(f\"\\nStarting MAE Loop ({len(steps)} steps)...\")\n",
    "\n",
    "for k in steps:\n",
    "    current_feats = sorted_feats[:k]\n",
    "    \n",
    "    model = LGBMRegressor(**best_params)\n",
    "    model.fit(X_train[current_feats], y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test[current_feats])\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    print(f\"   -> Top {k:3d} features: MAE = {mae:.2f}\")\n",
    "    results.append({'Num_Features': k, 'MAE': mae})\n",
    "\n",
    "df_results = pd.DataFrame(results).sort_values(by='Num_Features')\n",
    "df_leaderboard = df_results.sort_values(by='MAE', ascending=True).reset_index(drop=True)\n",
    "\n",
    "csv_filename = 'result/rfe_mae_results.csv'\n",
    "df_results.to_csv(csv_filename, index=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_results['Num_Features'], df_results['MAE'], marker='o', linewidth=2, color='purple')\n",
    "\n",
    "best_row = df_results.loc[df_results['MAE'].idxmin()]\n",
    "plt.scatter(best_row['Num_Features'], best_row['MAE'], color='red', s=150, zorder=5)\n",
    "plt.annotate(f\"Best MAE: {best_row['MAE']:.2f}\\n({int(best_row['Num_Features'])} feats)\", \n",
    "             (best_row['Num_Features'], best_row['MAE']), \n",
    "             xytext=(best_row['Num_Features']+20, best_row['MAE']+5),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "\n",
    "plt.title('RFE Feature Selection (MAE Metric)', fontsize=14)\n",
    "plt.xlabel('Number of Features', fontsize=12)\n",
    "plt.ylabel('Mean Absolute Error (MAE)', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTOP 5 CONFIGURATIONS (LOWEST MAE):\")\n",
    "print(df_leaderboard.head(5))\n",
    "\n",
    "print(\"\\nLOOP PROGRESS:\")\n",
    "print(df_results.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
